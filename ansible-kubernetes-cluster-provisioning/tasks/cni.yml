- name: Check for kubeconfig
  ansible.builtin.stat:
    path: "{{ home }}/.kube/config"
  register: kubeconfig
- name: Create calico-apiserver namespace
  when: kubeconfig.stat.exists
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    name: calico-apiserver
    api_version: v1
    kind: Namespace
    state: present
    definition:
      metadata:
        annotations:
          # cni.projectcalico.org/ipv4pools: '["system"]'
          metallb.universe.tf/address-pool: "system"
        labels:
          pod-security.kubernetes.io/enforce: privileged
          pod-security.kubernetes.io/audit: privileged
          pod-security.kubernetes.io/warn: privileged
- name: Patch calico-system namespace
  when: kubeconfig.stat.exists
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    name: calico-system
    api_version: v1
    kind: Namespace
    state: present
    definition:
      metadata:
        annotations:
          # cni.projectcalico.org/ipv4pools: '["system"]'
          metallb.universe.tf/address-pool: "system"
        labels:
          pod-security.kubernetes.io/enforce: privileged
          pod-security.kubernetes.io/audit: privileged
          pod-security.kubernetes.io/warn: privileged
- name: Create network-system namespace
  when: kubeconfig.stat.exists
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    name: network-system
    api_version: v1
    kind: Namespace
    state: present
    definition:
      metadata:
        annotations:
          # cni.projectcalico.org/ipv4pools: '["system"]'
          metallb.universe.tf/address-pool: "system"
        labels:
          pod-security.kubernetes.io/enforce: privileged
          pod-security.kubernetes.io/audit: privileged
          pod-security.kubernetes.io/warn: privileged
# - name: Configure RKE2-Multus
#   run_once: true
#   delegate_to: localhost
#   kubernetes.core.k8s:
#     kubeconfig: "{{ home }}/.kube/config"
#     api_version: helm.cattle.io/v1
#     kind: HelmChartConfig
#     name: rke2-multus
#     namespace: kube-system
#     state: present
- name: Configure RKE2-Calico
  run_once: true
  delegate_to: localhost
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    api_version: helm.cattle.io/v1
    kind: HelmChartConfig
    name: rke2-calico
    namespace: kube-system
    state: present
    definition:
      spec:
        valuesContent: |-
          apiServer:
            enabled: true
          installation:
            serviceCIDRs:
            - 10.254.0.0/16
            calicoNetwork:
              multiInterfaceMode: "Multus"
              # linuxDataplane: "BPF"
              bgp: "Enabled"
              # mtu: 9000
              nodeAddressAutodetectionV4:
                cidrs:
                - 10.0.0.0/18
                firstFound: false
              containerIPForwarding: "Enabled"
# - name: Patch Installation Configuration for Tigera Operator
#   when: kubeconfig.stat.exists
#   kubernetes.core.k8s:
#     kubeconfig: "{{ home }}/.kube/config"
#     state: patched
#     name: default
#     api_version: operator.tigera.io/v1
#     kind: Installation
#     # apply: true
#     # server_side_apply:
#     #   field_manager: ansible
#     definition:
#       spec:
#         serviceCIDRs:
#           - 10.254.0.0/16
#         calicoNetwork:
#           multiInterfaceMode: "Multus"
#           # linuxDataplane: "BPF"
#           bgp: "Enabled"
#           # mtu: 9000
#           nodeAddressAutodetectionV4:
#             kubernetes: NodeInternalIP
#             cidrs:
#             - 10.0.0.0/18
#             firstFound: false
#           containerIPForwarding: "Enabled"
- name: Get Latest Calico Release
  ansible.builtin.uri:
    url: https://api.github.com/repos/projectcalico/calico/releases/latest
    return_content: true
  register: calico_release_json
  failed_when: calico_release_json is failed
- name: Download tigera apiserver manifest to the cluster.
  ansible.builtin.get_url:
    url: https://raw.githubusercontent.com/projectcalico/calico/{{ calico_release_json.json.tag_name }}/manifests/apiserver.yaml
    dest: "{{ playbook_dir }}/apiserver.yaml"
    mode: '0664'
  register: tigeraapiservermanifest
# - name: Create APIServer for Tigera Operator
#   when: kubeconfig.stat.exists
#   kubernetes.core.k8s:
#     kubeconfig: "{{ home }}/.kube/config"
#     state: present
#     apply: true
#     server_side_apply:
#       field_manager: ansible
#     definition:
#       apiVersion: operator.tigera.io/v1
#       kind: APIServer
#       metadata:
#         name: default
#       spec: {}
#     # - name: Wait until HTTP status is 401
#     #   ansible.builtin.uri:
#     #     url: "https://{{ hostvars[groups['controlnodes'][0]]['ansible_host'] }}:6443"
#     #     return_content: yes
#     #     validate_certs: no
#     #     status_code:
#     #       - 401
#     #   until: uri_output.status == 401
#     #   retries: 20 # Retries for 20 * 15 seconds = 300 seconds = 5 minutes
#     #   delay: 15 # Every 15 seconds
#     #   register: uri_output
#     - name: Wait for create calico-kube-controllers to complete
#       kubernetes.core.k8s_info:
#         kubeconfig: "{{ home }}/.kube/config"
#         kind: Deployment
#         namespace: calico-system
#         label_selectors:
#           - k8s-app = calico-kube-controllers
#         wait: true
#         wait_condition:
#           type: "Available"
#           status: "True"
#         wait_sleep: 5
#         wait_timeout: 300
#       register: calicokubecontrollersstatus
#       until: calicokubecontrollersstatus.resources[0].status.readyReplicas | int > 0
#       retries: 20
#       delay: 15
- name: Apply tigera apiserver manifest to the cluster.
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    state: present
    src: "{{ playbook_dir }}/apiserver.yaml"
- name: Wait for apply tigera apiserver manifest to complete
  kubernetes.core.k8s_info:
    kubeconfig: "{{ home }}/.kube/config"
    kind: Deployment
    namespace: calico-apiserver
    label_selectors:
      - k8s-app = calico-apiserver
    wait: true
    wait_condition:
      type: "Available"
      status: "True"
    wait_sleep: 30
    wait_timeout: 600
  register: calicoapiserverstatus
  until: calicoapiserverstatus.resources[0].status.readyReplicas | int > 0
  retries: 20
  delay: 15
- name: Wait for apiservice apiserver to be available
  kubernetes.core.k8s_info:
    kubeconfig: "{{ home }}/.kube/config"
    kind: APIService
    name: v3.projectcalico.org
    wait: true
    wait_condition:
      type: "Available"
      status: "True"
    wait_sleep: 30
    wait_timeout: 600
  register: calicoapiservicestatus
  until: calicoapiservicestatus.resources[0].status.conditions[0].status == "True"
  retries: 20
  delay: 15
#     # - name: Create Default IPPool Config
#     #   when: kubeconfig.stat.exists
#     #   kubernetes.core.k8s:
#     #     kubeconfig: "{{ home }}/.kube/config"
#     #     state: present
#     #     apply: true
#     #     server_side_apply:
#     #       field_manager: ansible
#     #     definition:
#     #       apiVersion: projectcalico.org/v3
#     #       kind: IPPool
#     #       metadata:
#     #         name: default
#     #         namespace: kube-system
#     #       spec:
#     #         cidr: 10.0.101.0/24
#     #         ipipMode: Never
#     #         disabled: false
#     #         disableBGPExport: false
#     #         natOutgoing: false
#     #         nodeSelector: all()
#     #         allowedUses:
#     #         - Workload
#     #         - Tunnel
#     # - name: Create System IPPool Config
#     #   when: kubeconfig.stat.exists
#     #   kubernetes.core.k8s:
#     #     kubeconfig: "{{ home }}/.kube/config"
#     #     state: present
#     #     apply: true
#     #     server_side_apply:
#     #       field_manager: ansible
#     #     definition:
#     #       apiVersion: projectcalico.org/v3
#     #       kind: IPPool
#     #       metadata:
#     #         name: system
#     #         namespace: kube-system
#     #       spec:
#     #         cidr: 10.0.100.0/24
#     #         ipipMode: Never
#     #         disabled: false
#     #         disableBGPExport: false
#     #         natOutgoing: false
#     #         nodeSelector: all()
#     #         allowedUses:
#     #         - Workload
#     #         - Tunnel
- name: Create Global BGP Config
  when: kubeconfig.stat.exists
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    state: present
    # apply: true
    # server_side_apply:
    #   field_manager: ansible
    definition:
      apiVersion: projectcalico.org/v3
      kind: BGPConfiguration
      metadata:
        name: default
        namespace: calico-system
      spec:
        nodeToNodeMeshEnabled: false
        asNumber: 65001
        serviceLoadBalancerIPs:
          - cidr: 10.0.101.0/24
          - cidr: 10.0.100.0/24
        # communities:
        #   - name: bgpdefault
- name: Create Global BGP Peer Config
  when: kubeconfig.stat.exists
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    state: present
    # apply: true
    # server_side_apply:
    #   field_manager: ansible
    definition:
      apiVersion: projectcalico.org/v3
      kind: BGPPeer
      metadata:
        name: bgppeer
        namespace: calico-system
      spec:
        peerIP: 10.0.0.1
        asNumber: 65000
- name: Create Status Config
  when: kubeconfig.stat.exists
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    state: present
    # apply: true
    # server_side_apply:
    #   field_manager: ansible
    definition:
      apiVersion: projectcalico.org/v3
      kind: CalicoNodeStatus
      metadata:
        name: "{{ item }}-node-status"
        namespace: calico-system
      spec:
        classes:
          - Agent
          - BGP
          - Routes
        node: "{{ item }}"
        updatePeriodSeconds: 60
  loop: "{{ groups.kubernetes | list | flatten(1) }}"
- name: Configure Coredns
  run_once: true
  delegate_to: localhost
  kubernetes.core.k8s:
    kubeconfig: "{{ home }}/.kube/config"
    api_version: helm.cattle.io/v1
    kind: HelmChartConfig
    name: rke2-coredns
    namespace: kube-system
    state: present
    definition:
      spec:
        valuesContent: |-
          nodelocal:
            enabled: false
          service:
            clusterIP: 10.254.0.10
            # loadBalancerIP: 10.0.100.2
            # externalTrafficPolicy: Local
            serviceType: ClusterIP
            annotations:
              metallb.universe.tf/allow-shared-ip: coredns
          rbac:
            create: true
          prometheus:
            service:
              enabled: false
              annotations:
                prometheus.io/scrape: "true"
                prometheus.io/port: "9153"
            monitor:
              enabled: false
          autoscaler:
            enabled: true
            min: 2
            max: 5
          servers:
          - zones:
            - zone: .
            port: 53
            plugins:
            - name: errors
            # Serves a /health endpoint on :8080, required for livenessProbe
            - name: health
              configBlock: |-
                lameduck 5s
            # Serves a /ready endpoint on :8181, required for readinessProbe
            - name: ready
            # Required to query kubernetes API for data
            - name: kubernetes
              parameters: cluster.local in-addr.arpa ip6.arpa homelab.heyser.lan homelab.heyser.xyz
              configBlock: |-
                pods insecure
                fallthrough in-addr.arpa ip6.arpa homelab.heyser.lan homelab.heyser.xyz
                ttl 30
            - name: prometheus
              parameters: 0.0.0.0:9153
            - name: forward
              parameters: . /etc/resolv.conf 1.1.1.1
              configBlock: |-
                except "cluster.local" "svc.cluster.local" ".svc"
                policy sequential
            - name: cache
              parameters: 30
            - name: loop
            - name: reload
            - name: loadbalance
          zoneFiles:
          - filename: heyser.xyz
            domain: heyser.xyz
            contents: |
              heyser.xyz.   IN SOA  kyrie.ns.cloudflare.com. dns.cloudflare.com. 2325026458 10000 2400 604800 1800
              heyser.xyz. IN A   10.0.100.1
              homelab.heyser.xyz. IN A   10.0.100.1
              *.homelab.heyser.xyz. IN A   10.0.100.1
# - name: Exit Early
#   ansible.builtin.fail:
#     msg: Failing to diagnose
