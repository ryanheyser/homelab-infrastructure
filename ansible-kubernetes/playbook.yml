---
- name: Ping Hosts
  hosts: all
  tasks:
    - name: Ping all hosts
      delegate_to: localhost
      delegate_facts: true
      check_mode: false
      ansible.builtin.command: |
        ping -c 2 "{{ inventory_hostname }}"
      become: true
      failed_when: ping_hosts.rc == 1 or ping_hosts.rc > 2
      register: ping_hosts
      changed_when: false

- name: Setup SSH Access
  hosts: all
  tasks:
    - name: Setup | Read SSH Key
      ansible.builtin.set_fact:
        ansible_ssh_key_pub: "{{ lookup('template', playbook_dir + '/secrets/ansible_id_ed25519.pub') }}"
    - name: Setup | Add SSH Key to known hosts
      ansible.builtin.known_hosts:
        name: "{{ ansible_host }}"
        key: "{{ ansible_host }} {{ ansible_ssh_key_pub }}"
      changed_when: false

- name: Setup All Hosts
  hosts: all
  connection: ssh
  gather_facts: true
  vars:
    github_token: !vault |
      $ANSIBLE_VAULT;1.1;AES256
      31376165383330653737393839613239626332306636656261653037333761323631363637373164
      6561313737343638393335626665353735313633623036310a636336646434343338386636353033
      64623838633966303937336164616334343962336434346464663436316363396632643539386437
      3664633865653161610a316535366534353261643833623165623535633531393764656537666331
      36633134313138306436343363613030383265653063323564663233393232636233623964613562
      3265653936383532666136386661653036376536303961646664
  tasks:
    - name: Setup | apt update
      ansible.builtin.command: apt update -y
      become: true
      changed_when: true
    - name: Setup | apt upgrade
      ansible.builtin.command: apt upgrade -y
      become: true
      changed_when: true
    - name: Setup | install required packages
      ansible.builtin.apt:
        state: 'present'
        update_cache: true
        pkg:
          - age 
          - build-essential 
          - curl 
          - dnsutils
          - linux-generic
          - linux-headers-generic 
          - mtr-tiny 
          - net-tools
          - nfs-common
          - open-vm-tools
          - openssl 
          - p7zip-full 
          - pciutils 
          - python3 
          - python3-pip 
          - python3-venv 
          - python3-virtualenv
          - software-properties-common 
          - tcpdump 
          - vim 
          - zstd
      become: true
      changed_when: true
    - name: Setup | install ansible ppa
      ansible.builtin.apt_repository:
        repo: ppa:ansible/ansible
    - name: Setup | install ansible packages
      ansible.builtin.apt:
        state: 'present'
        update_cache: true
        pkg:
          - ansible
      become: true
      changed_when: true
    - name: Install sops
      ansible.builtin.include_role:
        name: community.sops.install
      vars:
        sops_install_on_localhost: true
        sops_github_token: "{{ github_token }}"
        sops_become_on_install: true
      when: >-
        not ((ansible_play_hosts_all | difference(ansible_play_hosts)) | length > 0)
    - name: Set hostname on remote hosts
      ansible.builtin.hostname:
        name: "{{ ansible_host }}"
      vars:
        sops_github_token: "{{ github_token }}"
        sops_become_on_install: true
      when: >-
        not ((ansible_play_hosts_all | difference(ansible_play_hosts)) | length > 0)

- name: Setup Kubernetes Hosts
  hosts: kubernetes
  connection: ssh
  # vars:
  tasks:
    - name: Setup | upgrade all packages
      ansible.builtin.apt:
        state: latest # noqa package-latest
        update_cache: true
        name: '*'
      become: true
    - name: Setup | install required packages
      ansible.builtin.apt:
        state: 'present'
        update_cache: true
        pkg:
          - bind9 
          - bind9-utils 
          - bind9-dnsutils 
          - containernetworking-plugins
      become: true
      changed_when: true
      register: packageinstall

# Age/Sops
- name: Age/Sops
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Stat age.key
      ansible.builtin.stat:
        path: "{{ home }}/.config/sops/age/keys.txt"
      register: age_key_file
    - name: Fail if Age Keyfile does not exist
      ansible.builtin.fail:
        message: "{{ home }}/.config/sops/age/keys.txt does not exist"
      when: not age_key_file.stat.exists
    - name: Get Age Public Key
      ansible.builtin.command: |
        grep -Po '(?<=public key: ).*' {{ home }}/.config/sops/age/keys.txt
      register: age_public_key
      when: age_key_file.stat.exists
      changed_when: true

# Flux
- name: Install Flux
  hosts: localhost
  tasks:
    - name: Install Flux CLI
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          curl -s https://fluxcd.io/install.sh | bash
        executable: /bin/bash
      become: true
      changed_when: true

# DNS
- name: Externaldns-key
  hosts: localhost
  strategy: linear
  tasks:
    - name: Generate externaldns-key
      # noqa: run-once[task]
      run_once: true
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          /usr/sbin/tsig-keygen -a hmac-sha256 externaldns | /usr/bin/grep secret | /usr/bin/cut -d '"' -f2
        executable: /bin/bash
      register: externaldns_key
      changed_when: false
- name: Setup DNS
  hosts: kubernetes
  tasks:
    - name: Setup BIND9
      vars:
        bind_dnssec_enable: false
        bind_dnssesc_validation: false
        bind_listen_ipv4:
          - any
        bind_allow_query:
          - any
        bind_allow_recursion:
          - any
        bind_dns_keys:
          - name: externaldns-key
            algorithm: hmac-sha256
            secret: "{{ externaldns_key }}"
        bind_zones:
          - name: homelab.heyser.lan
            type: primary
            primaries:
              "{{ groups.controlnodes | map('extract', hostvars) | map(attribute='ansible_host') | list }}"
          - name: homelab.heyser.lan
            type: secondary
            primaries:
              "{{ groups.workernodes | map('extract', hostvars) | map(attribute='ansible_host') | list }}"
      ansible.builtin.import_role:
        name: "bertvv.bind"
      when: >-
        packageinstall.stdout is defined and
        packageinstall.rc == 0 and
        not packageinstall is skipped

# k3s
- name: K3s | install kubernetes
  hosts: kubernetes
  tasks:
    - name: Deploy | Install K3s
      vars:
        k3s_become: true
        k3s_state: installed
          #k3s_primary_control_node: "{{ groups.controlnodes | first }}"
        k3s_registration_address: kubernetes.homelab.heyser.xyz
        # Set a specific release version or false for stable, latest for latest
        k3s_release_version: false
        k3s_build_cluster: true
        k3s_etcd_datastore: true
        k3s_use_unsupported_config: true
        k3s_use_experimental: true
        k3s_install_hard_links: true
        k3s_server:
          #listen-port: 6443
          bind-address: "{{ ansible_host }}"
          cluster-cidr: 10.254.0.0/16
          service-cidr: 10.255.0.0/16
          no-flannel: true
          flannel-backend: 'none'
          secrets-encryption: true
          etcd-expose-metrics: true
          disable-network-policy: true
          # disable-kube-proxy: true
          write-kubeconfig-mode: '0644'
          node-taint:
            - "node-role.kubernetes.io/control-plane:NoSchedule"
          node-label:
            - "node-role.kubernetes.io/control-plane=true"
            - "topology.kubernetes.io/region=us-east-1"
            - "topology.kubernetes.io/zone=us-east-1a"
            - "route-reflector=true"
          tls-san:
            - "kubernetes.homelab.heyser.xyz"
          disable:
            - traefik
            - coredns
            - servicelb
        k3s_agent:
          node-label:
            - "topology.kubernetes.io/region=us-east-1"
            - "topology.kubernetes.io/zone=us-east-1a"
            - "route-reflector=true"
      ansible.builtin.import_role:
        name: xanmanning.k3s
          #when: >-
          #not ((ansible_play_hosts_all | difference(ansible_play_hosts)) | length > 0)
      register: installk3s
    # - name: Cleanup | Remove multus-shim if exists
    #   ansible.builtin.file:
    #     path: "/opt/cni/bin/multus-shim"
    #     state: absent
- name: Post k3s install
  hosts: controlnodes
  gather_facts: false
  strategy: linear
  tasks:
    - name: Download kubeconfig
      # noqa: run-once[task]
      run_once: true
      become: true
      ansible.builtin.fetch:
        src: /etc/rancher/k3s/k3s.yaml
        dest: "{{ playbook_dir }}/k3s.yaml"
        flat: true
          # when: >-
          #installk3s is defined
- name: Post k3s install p2
  hosts: localhost
  gather_facts: false
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check if k3s.yaml File Exists
      ansible.builtin.stat:
        path: "{{ playbook_dir }}/k3s.yaml"
      register: k3s_yaml
        # when: >-
        # installk3s is defined
    - name: Create system kube directory
      ansible.builtin.file:
        path: "/etc/rancher/k3s"
        state: directory
        mode: '0755'
          #when: >-
          #installk3s is defined
    - name: Create user kube directory
      vars:
        home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
      ansible.builtin.file:
        path: "{{ home }}/.kube"
        state: directory
        mode: '0755'
          #when: >-
          #installk3s is defined
    - name: Copy Kubeconfig to system
      ansible.builtin.copy:
        src: "{{ playbook_dir }}/k3s.yaml"
        dest: "/etc/rancher/k3s/"
        force: true
        mode: '0644'
      when: >-
        k3s_yaml.stat.exists
    - name: Copy Kubeconfig to user default
      vars:
        home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
      ansible.builtin.command: |
        /usr/bin/cp "{{ playbook_dir }}/k3s.yaml" "{{ home }}/.kube/config"
      changed_when: true
      when: >-
        k3s_yaml.stat.exists
      #installk3s is defined and

- name: Post k3s install p3
  hosts: kubernetes
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check for kubeconfig
      delegate_to: localhost
      ansible.builtin.stat:
        path: "{{ home }}/.kube/config"
      register: kubeconfig
    - name: Patch nodes to add route-reflector
      delegate_to: localhost
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: patched
        kind: Node
        name: "{{ ansible_host }}"
        definition:
          metadata:
            annotations:
              projectcalico.org/RouteReflectorClusterID: 244.0.0.1

# Reflector
- name: Reflector
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check for kubeconfig
      ansible.builtin.stat:
        path: "{{ home }}/.kube/config"
      register: kubeconfig
    - name: Download reflector manifest to the cluster.
      ansible.builtin.get_url:
        url: https://github.com/emberstack/kubernetes-reflector/releases/latest/download/reflector.yaml
        dest: "{{ playbook_dir }}/reflector.yaml"
        mode: '0664'
      register: reflector
    - name: Apply reflector manifest to the cluster.
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        src: "{{ playbook_dir }}/reflector.yaml"
      register: reflectorapply      
    
# Docker Registry Credentials
- name: Create docker hub registry credential
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check docker secrets encrypted file
      ansible.builtin.stat:
        path: "{{ playbook_dir + '/secrets/docker.sops.yaml.enc' }}"
      register: dockersecretsfile
    - name: Unencrypt Docker Secrets
      ansible.builtin.set_fact:
          docker: "{{ lookup('file', playbook_dir + '/secrets/docker.sops.yaml.enc') | community.sops.decrypt | ansible.builtin.from_yaml }}"
      when: dockersecretsfile.stat.exists
      failed_when: not dockersecretsfile.stat.exists
    - name: Format docker config
      ansible.builtin.command: |
        echo -n '{"auths":{"https://index.docker.io/v1/":{"username":"{{ (docker | from_yaml).docker_user }}","email":"{{ (docker | from_yaml).docker_email }}","auth":"{{ (docker | from_yaml).docker_token }}"}}}'
      register: dockercfg
      changed_when: true
      failed_when:
        - dockercfg.rc != 0
        - dockercfg.stdout == ""
    - name: Create Secret
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: docker-registry-credentials
            namespace: kube-system
            annotations:
              reflector.v1.k8s.emberstack.com/reflection-allowed: "true"
              reflector.v1.k8s.emberstack.com/reflection-auto-enabled: "true"
          type: kubernetes.io/dockercfg
          data:
            .dockercfg: "{{ dockercfg.stdout | b64encode }}"

# CNI
- name: Configure Calico
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Get Latest Calico Release
      ansible.builtin.uri:
        url: https://api.github.com/repos/projectcalico/calico/releases/latest
        return_content: true
      register: calico_release_json
      failed_when: calico_release_json is failed
    - name: Get Latest Multus Release
      ansible.builtin.uri:
        url: https://api.github.com/repos/k8snetworkplumbingwg/multus-cni/releases/latest
        return_content: true
      register: multus_release_json
      failed_when: multus_release_json is failed
    # - name: Get Latest Traefik Release
    #   ansible.builtin.uri:
    #     url: https://api.github.com/repos/traefik/traefik/releases/latest
    #     return_content: true
    #   register: traefik_release_json
    #   failed_when: traefik_release_json is failed
    - name: Download tigera operator manifest to the cluster.
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/{{ calico_release_json.json.tag_name }}/manifests/tigera-operator.yaml
        dest: "{{ playbook_dir }}/tigera-operator.yaml"
        mode: '0664'
      register: tigeraoperatormanifest
    - name: Download tigera apiserver manifest to the cluster.
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/{{ calico_release_json.json.tag_name }}/manifests/apiserver.yaml
        dest: "{{ playbook_dir }}/apiserver.yaml"
        mode: '0664'
      register: tigeraapiservermanifest
    - name: Download multus daemonset thick manifest to the cluster.
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/{{ multus_release_json.json.tag_name }}/deployments/multus-daemonset-thick.yml
        dest: "{{ playbook_dir }}/multus-daemonset-thick.yml"
        mode: '0664'
      register: multusdaemonsetmanifest
    - name: Check for kubeconfig
      ansible.builtin.stat:
        path: "{{ home }}/.kube/config"
      register: kubeconfig
    - name: Apply tigera operator manifest to the cluster.
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        src: "{{ playbook_dir }}/tigera-operator.yaml"
    - name: Apply multus daemonset manifest to the cluster.
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        src: "{{ playbook_dir }}/multus-daemonset-thick.yml"
      register: multusdaemonsetmanifestapply      
    - name: Wait for apply tigera operator manifest to complete
      kubernetes.core.k8s_info:
        kubeconfig: "{{ home }}/.kube/config"
        kind: Deployment
        namespace: tigera-operator
        label_selectors:
          - k8s-app = tigera-operator
        wait: true
        wait_condition:
          type: "Available"
          status: "True"
        wait_sleep: 5
        wait_timeout: 300
    - name: Create Installation Configuration for Tigera Operator
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        apply: true
        server_side_apply: 
          field_manager: ansible
        definition:
          kind: Installation
          apiVersion: operator.tigera.io/v1
          metadata:
            name: default
          spec:
            linuxDataplane: "bpf"
            serviceCIDRs:
                - 10.255.0.0/16
            calicoNetwork:
              bgp: "enabled"
              mtu: 9000
              nodeAddressAutodetectionV4:
                cidrs:
                  - '10.0.0.0/18'
              ipPools:
                - name: default
                  cidr: 10.0.101.0/24
                  encapsulation: None
                  natOutgoing: Disabled
                  nodeSelector: all()
                  allowedUses:
                    - Workload
                    - Tunnel
                - name: system
                  cidr: 10.0.100.0/24
                  encapsulation: None
                  natOutgoing: Disabled
                  nodeSelector: all()
                  allowedUses:
                    - Workload
                    - Tunnel
    - name: Create APIServer for Tigera Operator
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        apply: true
        server_side_apply: 
          field_manager: ansible
        definition:
          apiVersion: operator.tigera.io/v1
          kind: APIServer
          metadata:
            name: default
          spec: {}
    - name: Wait for apply tigera apiserver manifest to complete
      kubernetes.core.k8s_info:
        kubeconfig: "{{ home }}/.kube/config"
        kind: Deployment
        namespace: calico-system
        label_selectors:
          - k8s-app = calico-kube-controllers
        wait: true
        wait_condition:
          type: "Available"
          status: "True"
        wait_sleep: 5
        wait_timeout: 300
    - name: Apply tigera apiserver manifest to the cluster.
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        src: "{{ playbook_dir }}/apiserver.yaml"
    - name: Wait for apply tigera apiserver manifest to complete
      kubernetes.core.k8s_info:
        kubeconfig: "{{ home }}/.kube/config"
        kind: Deployment
        namespace: calico-apiserver
        label_selectors:
          - k8s-app = calico-apiserver
        wait: true
        wait_condition:
          type: "Available"
          status: "True"
        wait_sleep: 30
        wait_timeout: 600

# Calico
- name: Configure Calico
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check for kubeconfig
      ansible.builtin.stat:
        path: "{{ home }}/.kube/config"
      register: kubeconfig
    - name: Create Global BGP Peer Config
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        apply: true
        server_side_apply:
          field_manager: ansible
        definition:
          apiVersion: projectcalico.org/v3
          kind: BGPPeer
          metadata:
            name: bgppeer
            namespace: kube-system
          spec:
            peerIP: 10.0.0.1
            asNumber: 65000

# Coredns
- name: Coredns Pre-steps
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check for kubeconfig
      ansible.builtin.stat:
        path: "{{ home }}/.kube/config"
      register: kubeconfig
    - name: Add coredns repository
      when: kubeconfig.stat.exists
      kubernetes.core.helm_repository:
        kubeconfig: "{{ home }}/.kube/config"
        name: coredns
        repo_url: https://coredns.github.io/helm
    - name: Create network-system namespace
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        name: kube-system
        api_version: v1
        kind: Namespace
        state: patched
        definition:
          annotations:
            cni.projectcalico.org/ipv4pools: '["system"]'
- name: Coredns Install
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check for kubeconfig
      ansible.builtin.stat:
        path: "{{ home }}/.kube/config"
      register: kubeconfig
    - name: Deploy Coredns chart
      when: kubeconfig.stat.exists
      kubernetes.core.helm:
        kubeconfig: "{{ home }}/.kube/config"
        name: coredns
        release_namespace: kube-system
        # renovate: registryUrl=https://coredns.github.io/helm
        chart_ref: coredns/coredns
        chart_version: 1.32.0
        values:
          servers:
          - zones:
            - zone: .
            port: 53
            plugins:
            - name: errors
            # Serves a /health endpoint on :8080, required for livenessProbe
            - name: health
              configBlock: |-
                lameduck 5s
            # Serves a /ready endpoint on :8181, required for readinessProbe
            - name: ready
            # Required to query kubernetes API for data
            - name: kubernetes
              parameters: cluster.local in-addr.arpa ip6.arpa homelab.heyser.lan homelab.heyser.xyz
              configBlock: |-
                pods insecure
                fallthrough in-addr.arpa ip6.arpa homelab.heyser.lan homelab.heyser.xyz
                ttl 30
            - name: forward
              parameters: . 10.0.100.3 10.0.0.1
              configBlock: |-
                force_tcp
                except "cluster.local" "svc.cluster.local" ".svc"
                policy sequential
            - name: cache
              parameters: 30
            - name: loop
            - name: reload
            - name: loadbalance

# Traefik
- name: Traefik Pre-steps
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check for kubeconfig
      ansible.builtin.stat:
        path: "{{ home }}/.kube/config"
      register: kubeconfig
    - name: Add traefik repository
      when: kubeconfig.stat.exists
      kubernetes.core.helm_repository:
        kubeconfig: "{{ home }}/.kube/config"
        name: traefik
        repo_url: https://helm.traefik.io/traefik
    - name: Create network-system namespace
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        name: network-system
        api_version: v1
        kind: Namespace
        state: present
        definition:
          annotations:
            cni.projectcalico.org/ipv4pools: '["system"]'
    - name: Create Traefik IP Reservation
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        apply: true
        server_side_apply:
          field_manager: ansible
          force_conflicts: true
        definition:
          apiVersion: projectcalico.org/v3
          kind: IPReservation
          metadata:
            name: traefik-ipv4-reservation
            namespace: network-system
          spec:
            reservedCIDRs:
              - 10.0.100.1
- name: Install Traefik CRDs
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Install Traefik CRD Definition
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        definition: '{{ item }}'
        namespace: network-system
        state: present
        apply: true
        force: true
        server_side_apply:
          field_manager: ansible
          force_conflicts: true
      with_items: >-
        {{
          lookup("url"), "https://aw.githubusercontent.com/traefik/traefik/" +
          traefik_release_json.stdout +
          "/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml"
        }}
      when: >-
        item is not none and
        kubeconfig.stat.exists
    - name: Install Traefik CRD RBAC
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        definition: '{{ item }}'
        namespace: network-system
        state: present
        apply: true
        force: true
        server_side_apply:
          field_manager: ansible
          force_conflicts: true
      with_items: >-
        {{
          lookup("url"), "https://aw.githubusercontent.com/traefik/traefik/" +
          traefik_release_json.stdout +
          "/docs/content/reference/dynamic-configuration/kubernetes-crd-rbac.yml"
        }}
      when: >-
        item is not none and
        kubeconfig.stat.exists
    - name: Install Traefik CRD Resource
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        definition: '{{ item }}'
        namespace: network-system
        state: present
        apply: true
        force: true
        server_side_apply:
          field_manager: ansible
          force_conflicts: true
      with_items: >-
        {{
          lookup("url"), "https://aw.githubusercontent.com/traefik/traefik/" +
          traefik_release_json.stdout +
          "/docs/content/reference/dynamic-configuration/kubernetes-crd-resource.yml"
        }}
      when: >-
        item is not none and
        kubeconfig.stat.exists
- name: Install Traefik
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Deploy Traefik chart
      when: kubeconfig.stat.exists
      kubernetes.core.helm:
        kubeconfig: "{{ home }}/.kube/config"
        name: traefik
        release_namespace: network-system
        # renovate: registryUrl=https://helm.traefik.io/traefik
        chart_ref: traefik/traefik
        chart_version: 30.1.0
        values_files:
          - "{{ playbook_dir }}/helm_values/traefik/values.yaml"
    - name: Configure crowdsec bouncer for traefik
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        namespace: network-system
        definition: "{{ lookup('file', playbook_dir + '/helm_values/traefik/crowdsec-bouncer.yaml') | from_yaml_all }}"
        validate:
          fail_on_error: false
    - name: Configure authentik for traefik
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        namespace: network-system
        definition: "{{ lookup('file', playbook_dir + '/helm_values/traefik/authentik.yaml') | from_yaml_all }}"
        validate:
          fail_on_error: false

# Patch Operator
- name: Patch Operator | Pre-steps
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Check for kubeconfig
      ansible.builtin.stat:
        path: "~/.kube/config"
      register: kubeconfig
    - name: Add patch operator repository
      # when: kubeconfig.stat.exists
      kubernetes.core.helm_repository:
        kubeconfig: "{{ home }}/.kube/config"
        name: patch-operator
        repo_url: https://redhat-cop.github.io/patch-operator
    - name: Create network-system namespace
      # when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        name: patch-operator-system
        api_version: v1
        kind: Namespace
        state: present
        definition:
          annotations:
            cni.projectcalico.org/ipv4pools: '["system"]'
- name: Patch Operator | Install
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Deploy Patch Operator chart
      # when: kubeconfig.stat.exists
      kubernetes.core.helm:
        kubeconfig: "{{ home }}/.kube/config"
        name: patch-operator
        release_namespace: patch-operator-system
        # renovate: registryUrl=https://redhat-cop.github.io/patch-operator
        chart_ref: patch-operator/patch-operator
        chart_version: v0.1.11
        values:
          enableMonitoring: false
    - name: Install Patch ServiceAccount
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: "present"
        definition:
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: patching-service-account
            namespace: patch-operator-system
    - name: Install Patch ServiceAccount ClusterRole
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: "present"
        definition:
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          metadata:
            name: service-account-modifier
          rules:
            - apiGroups: [""]
              resources: ["serviceaccounts"]
              verbs: ["get", "watch", "list", "update", "patch"]
    - name: Install Patch ServiceAccount ClusterRole
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: "present"
        definition:
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: service-account-modifier-binding
          subjects:
            - kind: ServiceAccount
              name: patching-service-account
              namespace: patch-operator-system
          roleRef:
            kind: ClusterRole
            name: service-account-modifier
            apiGroup: rbac.authorization.k8s.io
    - name: Wait for patch-operator manifest to complete
      kubernetes.core.k8s_info:
        kubeconfig: "{{ home }}/.kube/config"
        kind: Deployment
        namespace: patch-operator-system
        label_selectors:
          - app.kubernetes.io/instance = patch-operator
        wait: true
        wait_condition:
          type: "Available"
          status: "True"
        wait_sleep: 5
        wait_timeout: 300
    - name: Install Image Pull Secret Patch
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: "present"
        definition:
          apiVersion: redhatcop.redhat.io/v1alpha1
          kind: Patch
          metadata:
            name: dockerhub-image-pull-secret-patch
            namespace: patch-operator-system
          spec:
            serviceAccountRef:
              name: patching-service-account
            patches:
              service-account-patch:
                targetObjectRef: 
              apiVersion: v1
              kind: ServiceAccount
            patchType: application/strategic-merge-patch+json
            patchTemplate: |
              imagePullSecrets:
                - name: docker-registry-credentials

# Flux
- name: Bootstrap Flux
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Flux pre-checks
      ansible.builtin.command: flux check --pre
      become: true
      register: flux_precheck_out
      changed_when: true
      failed_when:
        - flux_precheck_out.rc != 0
    - name: Check github secrets encrypted file
      ansible.builtin.stat:
        path: "{{ playbook_dir + '/secrets/github.sops.yaml.enc' }}"
      register: githubsecretsfile
    - name: Unencrypt Docker Secrets
      ansible.builtin.set_fact:
          github: "{{ lookup('file', playbook_dir + '/secrets/github.sops.yaml.enc') | community.sops.decrypt | ansible.builtin.from_yaml }}"
      when: githubsecretsfile.stat.exists
      failed_when: not githubsecretsfile.stat.exists
    - name: Flux bootstrap
      environment:
        GITHUB_TOKEN: "{{ (github | from_yaml).GITHUB_TOKEN }}"
      ansible.builtin.command: |
        flux bootstrap github \
          --owner=ryanheyser \
          --repository=homelab-ops \
          --branch main \
          --private=false \
          --personal \
          --network-policy=false
      register: flux_bootstrap_out
      changed_when: true
      failed_when:
        - flux_bootstrap_out.rc != 0

# Vault
- name: Install Vault
  hosts: localhost
  strategy: linear
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Add hashicorp repository
      when: kubeconfig.stat.exists
      kubernetes.core.helm_repository:
        kubeconfig: "{{ home }}/.kube/config"
        name: hashicorp
        repo_url: https://helm.releases.hashicorp.com
    - name: Create vault-system namespace
      when: kubeconfig.stat.exists
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        name: vault-system
        api_version: v1
        kind: Namespace
        state: present
        definition:
          annotations:
            cni.projectcalico.org/ipv4pools: '["system"]'
    - name: Deploy vault chart
      when: kubeconfig.stat.exists
      kubernetes.core.helm:
        kubeconfig: "{{ home }}/.kube/config"
        name: vault
        release_namespace: vault-system
        # renovate: registryUrl=https://helm.releases.hashicorp.com
        chart_ref: hashicorp/vault
        chart_version: 0.28.1
        values_files:
          - "{{ playbook_dir }}/ansible/helm_values/vault/values.yaml"
    - name: Deploy csi-secrets-store chart
      when: kubeconfig.stat.exists
      kubernetes.core.helm:
        kubeconfig: "{{ home }}/.kube/config"
        name: csi-secrets-store
        release_namespace: kube-system
        # renovate: registryUrl=https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts
        chart_ref: secrets-store-csi-driver/secrets-store-csi-driver
        chart_version: 1.4.5
        values_files:
          - "{{ playbook_dir }}/ansible/helm_values/vault/csivalues.yaml"
    - name: Check if Vault Operator Init File Exists
      ansible.builtin.stat:
        path: "{{ playbook_dir }}/secrets/vault-operator-init-secret.key"
      register: vault_operator_init_file
    - name: Initialize Vault
      # noqa: run-once[task]
      run_once: true
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: vault operator init -format=json -key-shares=10 -key-threshold=3 -recovery-shares=10 -recovery-threshold=3
      register: vault_operator_init
      when: >-
        vault_operator_init_file.stat.exists and
        kubeconfig.stat.exists
    - name: Write Vault Configuration to File
      # noqa: run-once[task]
      run_once: true
      ansible.builtin.copy:
        content: "{{ vault_operator_init.stdout }}"
        dest: "{{ playbook_dir }}/secrets/vault-operator-init-secret.key"
        mode: preserve
      when: >-
        vault_operator_init is defined and
        not vault_operator_init is skipped
      register: vault_operator_init_config
    - name: Write Vault Configuration to Encrypted File
      # noqa: run-once[task]
      run_once: true
      community.sops.sops_encrypt:
        content_json: "{{ vault_operator_init.stdout }}"
        path: "{{ playbook_dir }}/secrets/vault-operator-init-secret.key.enc"
        age: age_public_key.stdout
      when: >-
        vault_operator_init_config is defined and
        not vault_operator_init_config is skipped
    - name: Read Vault Configuration from File
      # noqa: run-once[task]
      run_once: true
      ansible.builtin.set_fact:
        vault_operator_init: "lookup('file', {{ playbook_dir }}'/secrets/vault-operator-init-secret.key')"
      when: vault_operator_init_file.stat.exists
    - name: Check Vault Status
      when: kubeconfig.stat.exists
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: vault status -format=json
      register: vault_status
- name: Unseal Vault
  hosts: localhost
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Unseal Vault 1
      when: >-
        vault_status.stdout is defined and
        (vault_status.stdout | from_json).sealed and
        kubeconfig.stat.exists
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: vault operator unseal {{ (vault_operator_init.stdout | from_json).unseal_keys_b64[0] }} -format=json
    - name: Unseal Vault 2
      when: >-
        vault_status.stdout is defined and
        (vault_status.stdout | from_json).sealed and
        kubeconfig.stat.exists
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: vault operator unseal {{ (vault_operator_init.stdout | from_json).unseal_keys_b64[1] }} -format=json
    - name: Unseal Vault 3
      when: >-
        vault_status.stdout is defined and
        (vault_status.stdout | from_json).sealed and
        kubeconfig.stat.exists
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: vault operator unseal {{ (vault_operator_init.stdout | from_json).unseal_keys_b64[2] }} -format=json
    - name: Check Vault Status Again
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: vault status -format=json
      register: vault_status_after_unseal
      failed_when: (vault_status_after_unseal | from_json).sealed
      when: >-
        kubeconfig.stat.exists
    - name: Check if Vault Operator Root File Exists
      ansible.builtin.stat:
        path: "{{ playbook_dir }}/secrets/vault-operator-root-generate.key"
      register: vault_operator_root_file
- name: Unseal Vault
  hosts: localhost
  strategy: linear
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Initialize Vault Root Token
      # noqa: run-once[task]
      run_once: true
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: vault operator generate-root -init -format=json
      register: vault_operator_root
      when: >-
        not vault_operator_root_file.stat.exists and
        kubeconfig.stat.exists
    - name: Write Vault Root Generation to File
      # noqa: run-once[task]
      run_once: true
      ansible.builtin.copy:
        content: vault_operator_root.stdout
        dest: "{{ playbook_dir }}/secrets/vault-operator-root-generate.key"
        mode: preserve
      when: >-
        vault_operator_root is defined and
        not vault_operator_root is skipped
    - name: Read Vault Root Token from File
      # noqa: run-once[task]
      run_once: true
      ansible.builtin.set_fact:
        vault_operator_root: "lookup('file', {{ playbook_dir }}'/secrets/vault-operator-root-generate.key')"
      when: vault_operator_root_file.stat.exists
    - name: Set Vault Root Token OTP
      # noqa: run-once[task]
      run_once: true
      ansible.builtin.set_fact:
        vault_operator_root_otp: "lookup('file', {{ playbook_dir }}'/secrets/vault-operator-root-generate.key')"
      when: vault_operator_root_file.stat.exists
    - name: Generate Root Token 1
      # noqa: run-once[task]
      run_once: true
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: >-
          vault operator generate-root -otp={{ (vault_operator_root_otp.stdout | from_json).otp }} \
            -decode={{ (vault_operator_init.stdout | from_json).unseal_keys_b64[0] }} -format=json
      when: >-
        vault_operator_root.stdout is defined and
        vault_operator_init.stdout is defined and
        not (vault_operator_root.stdout | from_json).complete and
        kubeconfig.stat.exists
      register: vault_operator_root
    - name: Generate Root Token 2
      # noqa: run-once[task]
      run_once: true
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: >-
          vault operator generate-root -otp={{ (vault_operator_root_otp.stdout | from_json).otp }} \
            -decode={{ (vault_operator_init.stdout | from_json).unseal_keys_b64[1] }} -format=json
      when: >-
        vault_operator_root.stdout is defined and
        vault_operator_init.stdout is defined and
        not (vault_operator_root.stdout | from_json).complete and
        kubeconfig.stat.exists
      register: vault_operator_root
    - name: Generate Root Token 3
      # noqa: run-once[task]
      run_once: true
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: >-
          vault operator generate-root -otp={{ (vault_operator_root_otp.stdout | from_json).otp }} \
            -decode={{ (vault_operator_init.stdout | from_json).unseal_keys_b64[2] }} -format=json
      when: >-
        vault_operator_root.stdout is defined and
        vault_operator_init.stdout is defined and
        not (vault_operator_root.stdout | from_json).complete and
        kubeconfig.stat.exists
      register: vault_operator_root
    - name: Write Vault Encrypted Root Token to File
      # noqa: run-once[task]
      run_once: true
      community.sops.sops_encrypt:
        content_json: "{{ vault_operator_root.stdout | to_json }}"
        path: "{{ playbook_dir }}/secrets/vault-operator-root-token.key.enc"
        age: age_public_key.stdout
      when: >-
        vault_operator_root.stdout is defined and
        vault_operator_init.stdout is defined and
        (vault_operator_root.stdout | from_json).complete
- name: Create Vault Token Secret
  hosts: localhost
  strategy: linear
  vars:
    home: "{{ lookup('ansible.builtin.env', 'HOME') }}"
  tasks:
    - name: Login to Vault
      # noqa: run-once[task]
      run_once: true
      kubernetes.core.k8s_exec:
        kubeconfig: "{{ home }}/.kube/config"
        namespace: vault-system
        pod: vault-0
        command: >-
          vault login -format=json -address=http://vault.vault-system.svc.cluster.local:8200 \
            {{ (vault_operator_init.stdout | from_json).root_token }}
      when: >-
        vault_operator_root.stdout is defined and
        vault_operator_init.stdout is defined and
        (vault_operator_root.stdout | from_json).complete and
        (vault_operator_root.stdout | from_json).encoded_token != "" and
        (vault_operator_init.stdout | from_json).root_token != "" and
        kubeconfig.stat.exists
      register: vault_login
      failed_when: (vault_login.stdout | from_json).auth.client_token == ""
    - name: Create Vault Token Secret
      # noqa: run-once[task]
      run_once: true
      kubernetes.core.k8s:
        kubeconfig: "{{ home }}/.kube/config"
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: vault-token
            namespace: kube-system
          type: opaque
          data:
            token: "{{ (vault_operator_init.stdout | from_json).root_token | b64encode }}"
      when: >-
        kubeconfig.stat.exists and
        vault_operator_init.stdout is defined
      failed_when: >-
        {{(vault_operator_init.stdout | from_json).root_token | b64encode}} == ""
